import torch
import os
from skimage import io
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader, ConcatDataset, TensorDataset
import numpy as np
import torchvision.transforms as transforms
import torch.nn.functional as F
import matplotlib.pyplot as plt
%matplotlib inline
from torchvision import models
import torch.nn as nn
USE_CUDA = torch.cuda.is_available()
DEVICE = torch.device("cuda" if USE_CUDA else "cpu")
import math
from torch.optim.lr_scheduler import StepLR

BATCH_SIZE = 32

transform_train = transforms.Compose([ 
    transforms.ToPILImage(),
    transforms.RandomHorizontalFlip(0.2),
    transforms.RandomVerticalFlip(0.2),
    transforms.RandomRotation(180),
    
    transforms.ColorJitter(0.1, 0.1, 0.1),
    transforms.ToTensor(),
    transforms.RandomErasing(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])

transform_test = transforms.Compose([ 
    transforms.ToPILImage(),
    transforms.ToTensor(),
    
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])

#stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))
#train_tfms = tt.Compose([tt.RandomCrop(32, padding=4, padding_mode='reflect'), 
#                        tt.RandomHorizontalFlip(), 
#                         tt.ToTensor(), 
#                         tt.Normalize(*stats,inplace=True)])
#valid_tfms = tt.Compose([tt.ToTensor(), tt.Normalize(*stats)])
# transform = transforms.Compose([
#   transforms.RandomHorizontalFlip(),
#   transforms.ToTensor(),
#   transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
#   transforms.RandomErasing(),
# ])
     

class MyDataset(Dataset):
  def __init__(self, image_dir, label, transform=False):
    self.image_dir = image_dir
    self.label = label
    self.image_list = os.listdir(self.image_dir)
    self.transform = transform
  
  def __len__(self):
    return len(self.image_list)


  
  def __getitem__(self,idx):
    # if torch.is_tensor(idx):
    #   idx = idx.tolist()

    image_name = os.path.join(self.image_dir, self.image_list[idx])
    image = io.imread(image_name)

    ### transform
    image = self.transform(image)

    return (image,self.label)


root = '/kaggle/input/swdl2020'
test404 = '/kaggle/input/swdl20202'
#cheetah : 0 , jaguar : 1, tiger : 2, hyena : 3

cheetah_train = MyDataset(root+"/train/cheetah_train_resized",0,transform_train)
jaguar_train = MyDataset(root+"/train/jaguar_train_resized",1,transform_train)
tiger_train = MyDataset(root+"/train/tiger_train_resized",2,transform_train)
hyena_train = MyDataset(root+"/train/hyena_train_resized",3,transform_train)

train_set = ConcatDataset([cheetah_train, jaguar_train, tiger_train, hyena_train])
print("Number of Training set images : ", len(train_set))

cheetah_val = MyDataset(root+"/validation/cheetah_validation_resized",0, transform_test)
jaguar_val = MyDataset(root+"/validation/jaguar_validation_resized",1, transform_test)
tiger_val = MyDataset(root+"/validation/tiger_validation_resized",2, transform_test)
hyena_val = MyDataset(root+"/validation/hyena_validation_resized",3,transform_test)
val_set = ConcatDataset([cheetah_val, jaguar_val, tiger_val, hyena_val])
print("Numver of Validation set images : ", len(val_set))

train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle = True)
val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)

images, label = train_set[34]
plt.imshow(images.permute(1, 2, 0), cmap='gray')
print("label: ", label)

#####  MODEL#####
class block(nn.Module):
    def __init__(
        self, in_channels, intermediate_channels, identity_downsample=None, stride=1
    ):
        super(block, self).__init__()
        self.expansion = 4
        self.conv1 = nn.Conv2d(
            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0
        )
        self.bn1 = nn.BatchNorm2d(intermediate_channels)
        self.conv2 = nn.Conv2d(
            intermediate_channels,
            intermediate_channels,
            kernel_size=3,
            stride=stride,
            padding=1,
        )
        self.bn2 = nn.BatchNorm2d(intermediate_channels)
        self.conv3 = nn.Conv2d(
            intermediate_channels,
            intermediate_channels * self.expansion,
            kernel_size=1,
            stride=1,
            padding=0,
        )
        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)
        self.relu = nn.ReLU()
        self.identity_downsample = identity_downsample
        self.stride = stride

    def forward(self, x):
        identity = x.clone()

        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.conv3(x)
        x = self.bn3(x)

        if self.identity_downsample is not None:
            identity = self.identity_downsample(identity)

        x += identity
        x = self.relu(x)
        return x


class ResNet(nn.Module):
    def __init__(self, block, layers, image_channels, num_classes):
        super(ResNet, self).__init__()
        self.in_channels = 64
        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU()
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        # entire ResNet architecture are in these 4 lines below
        self.layer1 = self._make_layer(
            block, layers[0], intermediate_channels=64, stride=1
        )
        self.layer2 = self._make_layer(
            block, layers[1], intermediate_channels=128, stride=2
        )
        self.layer3 = self._make_layer(
            block, layers[2], intermediate_channels=256, stride=2
        )
        self.layer4 = self._make_layer(
            block, layers[3], intermediate_channels=512, stride=2
        )

        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.dropout = nn.Dropout2d(p=0.5,inplace=True)
        self.fc = nn.Linear(512 * 4, num_classes)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = self.dropout(x)
        x = x.reshape(x.shape[0], -1)
        x = self.fc(x)
#         print(np.shape(x))
        x = nn.Softmax(1)(x)      
        
        return x
    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):
        identity_downsample = None
        layers = []

        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2)
        if stride != 1 or self.in_channels != intermediate_channels * 4:
            identity_downsample = nn.Sequential(
                nn.Conv2d(
                    self.in_channels,
                    intermediate_channels * 4,
                    kernel_size=1,
                    stride=stride,
                ),
                nn.BatchNorm2d(intermediate_channels * 4),
            )

        layers.append(
            block(self.in_channels, intermediate_channels, identity_downsample, stride)
        )

        # The expansion size is always 4 for ResNet 50
        self.in_channels = intermediate_channels * 4

        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,
        for i in range(num_residual_blocks - 1):
            layers.append(block(self.in_channels, intermediate_channels))

        return nn.Sequential(*layers)



def ResNet50(img_channel, num_classes):
    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)




model = ResNet50(3, 4)
model.to(DEVICE)


def train(model, train_loader, optimizer, epoch):
  model.train()
  for batch_idx, (image, target) in enumerate(train_loader):
    data, target = image.to(DEVICE), target.to(DEVICE)
    optimizer.zero_grad()
    output = model(data)
    loss = F.cross_entropy(output, target)
    loss.backward()
    optimizer.step()

    if batch_idx % 150 == 0 :
      print('Train Epoch : {} [{}/{} ({:.0f})%]\tLoss: {:.6f}'
      .format(epoch, batch_idx*len(image),len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.item()))

def evaluate(model, test_loader):
  model.eval()
  test_loss =0
  correct =0
  with torch.no_grad():
    for (image, target) in test_loader:
      image, label = image.to(DEVICE), target.to(DEVICE)
      output = model(image)

      test_loss += F.cross_entropy(output, label, reduction='sum').item()
      pred = output.max(1, keepdim=True)[1]
      correct+= pred.eq(label.view_as(pred)).sum().item()
  
  test_loss /= len(test_loader.dataset)
  test_accuracy = 100. * correct / len(test_loader.dataset)
  return test_loss, test_accuracy

EPOCH = 20
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
scheduler = StepLR(optimizer, step_size=1, gamma=0.1)

for epoch in range(1, EPOCH):
    train(model, train_loader, optimizer, epoch)
    test_loss, test_accuracy = evaluate(model, val_loader)
    scheduler.step()
    print('[{}] Test Loss : {:.4f}, Accuracy : {:.4f}%'.format(epoch, test_loss, test_accuracy))

class TestDataset(Dataset):
  def __init__(self, image_dir, transform=None):
    self.image_dir = image_dir
    self.image_list = os.listdir(self.image_dir)
    self.transform = transform
  
  def __len__(self):
    return len(self.image_list)
  
  def __getitem__(self,idx):
    # if torch.is_tensor(idx):
    #   idx = idx.tolist()

    image_name = os.path.join(self.image_dir, self.image_list[idx])
    image = io.imread(image_name)

    ### transform
    image = self.transform(image)

    return (image,self.image_list[idx].split('.')[0])


test_set = TestDataset(test404, transform_test)
test_loader = DataLoader(test_set)


def predict_image(img, model):
    # Convert to a batch of 1
    xb = img.unsqueeze(0).to(DEVICE);
    # Get predictions from model
    yb = model(xb)
    # Pick index with highest probability
    _, preds  = torch.max(yb, dim=1)
    # Retrieve the class label
    return [preds[0].tolist().item()]

img, label = test_set[2]
# plt.imshow(img, cmap='gray')
plt.imshow(img.permute(1, 2, 0), cmap='gray')
# print('Label:', ', Predicted:', predict_image(img, model))

import pandas as pd

#cheetah : 0 , jaguar : 1, tiger : 2, hyena : 3
map = ['cheetah','jaguar','iger','hyena']

model.eval()
df = pd.DataFrame(columns=['id','category'])
with torch.no_grad():
    for (image, image_name) in test_loader:
        image = image.to(DEVICE)
        output = model(image)
        pred = output.max(1, keepdim=True)[1]
        df = df.append(pd.DataFrame([[image_name[0], map[pred.squeeze().tolist()]]], columns=['id','category']))

df


df.to_csv('/kaggle/working/'+'res.csv', index=False)
